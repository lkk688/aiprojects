import torch
import torch.nn as nn
from fla.layers import GatedLinearAttention
import os

# ================= é…ç½® =================
CONFIG = {
    "d_model": 64,     # æå°æ¨¡å‹
    "n_heads": 2,
    "seq_len": 32,     # æçŸ­åºåˆ—
    "device": "cuda"
}

print(f"ğŸ” Diagnostic Test running on {CONFIG['device']}...")

# ================= å®šä¹‰æœ€å°åŒ–æ¨¡å‹ =================
class DebugModel(nn.Module):
    def __init__(self):
        super().__init__()
        # ä½¿ç”¨ float32 (FP32) ä»¥æ’é™¤ BF16 çš„æ•°å€¼ç¨³å®šæ€§é—®é¢˜
        self.layer = GatedLinearAttention(
            hidden_size=CONFIG['d_model'], 
            num_heads=CONFIG['n_heads'], 
            mode='chunk'
        )
        self.head = nn.Linear(CONFIG['d_model'], 10)

    def forward(self, x):
        # âœ… ä¿®å¤ï¼šå…¼å®¹æ‰€æœ‰è¿”å›å€¼æ•°é‡ï¼Œåªå–ç¬¬ä¸€ä¸ª
        outputs = self.layer(x)
        if isinstance(outputs, tuple):
            x = outputs[0]
        else:
            x = outputs
        return self.head(x)

def run_diagnostic():
    # 1. åˆå§‹åŒ–æ¨¡å‹ (FP32)
    model = DebugModel().to(CONFIG['device']).float()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # 2. é€ å‡æ•°æ® (FP32)
    x = torch.randn(2, CONFIG['seq_len'], CONFIG['d_model'], device=CONFIG['device']).float()
    target = torch.randint(0, 10, (2, CONFIG['seq_len']), device=CONFIG['device'])
    
    print("\nğŸ§ª Step 1: Forward Pass (å‰å‘ä¼ æ’­)...")
    try:
        logits = model(x)
        loss = nn.CrossEntropyLoss()(logits.view(-1, 10), target.view(-1))
        print(f"  âœ… Forward successful. Loss: {loss.item():.4f}")
    except Exception as e:
        print(f"  âŒ Forward Failed: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nğŸ§ª Step 2: Backward Pass (åå‘ä¼ æ’­)...")
    try:
        loss.backward()
        print("  âœ… Backward successful.")
    except Exception as e:
        print(f"  âŒ Backward Failed: {e}")
        return

    print("\nğŸ§ª Step 3: Gradient Check (æ¢¯åº¦æ£€æŸ¥)...")
    has_grad = False
    
    # æ£€æŸ¥å…³é”®å‚æ•°ï¼šGate (g) å’Œ Value (v) çš„æŠ•å½±å±‚
    # å¦‚æœè¿™äº›å±‚æœ‰æ¢¯åº¦ï¼Œè¯´æ˜çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ç”Ÿæ•ˆäº†
    print(f"  {'Param Name':<40} | {'Grad Mean':<12} | {'Status'}")
    print("-" * 70)
    
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_mean = param.grad.abs().mean().item()
            status = "âœ… OK" if grad_mean > 0 else "âš ï¸ ZERO"
            print(f"  {name:<40} | {grad_mean:.6f}     | {status}")
            if grad_mean > 0:
                has_grad = True
        else:
            print(f"  {name:<40} | None         | âŒ NO GRAD")
            
    if has_grad:
        print("\nğŸ‰ DIAGNOSIS: Gradients are flowing! The kernel is HEALTHY.")
        print("   Next Step: Run your benchmark script again.")
    else:
        print("\nâŒ DIAGNOSIS: All Gradients are ZERO or None.")
        print("   Reason: The Triton kernel is compiled incorrectly.")

if __name__ == "__main__":
    run_diagnostic()