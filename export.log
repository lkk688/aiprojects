Multiple distributions found for package optimum. Picked distribution: optimum-onnx
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.5.1+cu124)
    Python  3.12.9 (you have 3.12.9)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
`torch_dtype` is deprecated! Use `dtype` instead!
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Moving the following attributes in the config to the generation config: {'max_length': 448, 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.
/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:669: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if input_features.shape[-1] != expected_seq_length:
/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:81: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  is_causal = query.shape[2] > 1 and attention_mask is None and getattr(module, "is_causal", True)
/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/transformers/cache_utils.py:132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if not self.is_initialized or self.keys.numel() == 0:
/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:86: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  is_causal = is_causal.item()
Traceback (most recent call last):
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/exporters/onnx/convert.py", line 1119, in onnx_export_from_model
    models_and_onnx_configs, onnx_files_subpaths = onnx_config.post_process_exported_models(
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/exporters/onnx/base.py", line 768, in post_process_exported_models
    models_and_onnx_configs, onnx_files_subpaths = super().post_process_exported_models(
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/exporters/onnx/base.py", line 409, in post_process_exported_models
    onnx_model = onnx.load(os.path.join(path, subpath))
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/onnx/__init__.py", line 233, in load_model
    load_external_data_for_model(model, base_dir)
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/onnx/external_data_helper.py", line 75, in load_external_data_for_model
    load_external_data_for_tensor(tensor, base_dir)
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/onnx/external_data_helper.py", line 53, in load_external_data_for_tensor
    external_data_file_path = c_checker._resolve_external_data_location(  # type: ignore[attr-defined]
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
onnx.onnx_cpp2py_export.checker.ValidationError: Data of TensorProto ( tensor name: model.decoder.embed_tokens.weight) should be stored in /fs/atipa/data/rnd-liu/aiprojects/whisper_onnx_model/model.decoder.embed_tokens.weight, but it doesn't exist or is not accessible.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/010796032/.conda/envs/py312/bin/optimum-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/commands/optimum_cli.py", line 219, in main
    service.run()
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/commands/export/onnx.py", line 264, in run
    main_export(
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/exporters/onnx/__main__.py", line 399, in main_export
    onnx_export_from_model(
  File "/home/010796032/.conda/envs/py312/lib/python3.12/site-packages/optimum/exporters/onnx/convert.py", line 1123, in onnx_export_from_model
    raise RuntimeError(
RuntimeError: The post-processing of the ONNX export failed. The export can still be performed by passing the option --no-post-process

ERROR conda.cli.main_run:execute(125): `conda run optimum-cli export onnx --model openai/whisper-large-v3 whisper_onnx_model` failed. (See above for error)
